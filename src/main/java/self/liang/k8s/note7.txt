coreDns

1 coredns用途
    1.1 为什么需要服务发现
    在K8S集群中，POD有以下特性：
    1. 服务动态性强
    容器在k8s中迁移会导致POD的IP地址变化
    2. 更新发布频繁
    版本迭代快，新旧POD的IP地址会不同
    3. 支持自动伸缩
    大促或流量高峰需要动态伸缩，IP地址会动态增减
    service资源解决POD服务发现：
    为了解决pod地址变化的问题，需要部署service资源，用service资源代理后端pod，通过暴露service资源的固定地址(集群IP)，来解决以上POD资源变化产生的IP变动问题
    那service资源的服务发现呢？
    service资源提供了一个不变的集群IP供外部访问，但
    1. IP地址毕竟难以记忆
    2. service资源可能也会被销毁和创建
    3. 能不能将service资源名称和service暴露的集群网络IP对于
    4. 类似域名与IP关系，则只需记服务名就能自动匹配服务IP
    5. 岂不就达到了service服务的自动发现
    在k8s中，coredns就是为了解决以上问题。

2.部署k8s 内网资源配置清单http服务
   2.0 配置nginx
    /etc/nginx/conf.d/k8syaml.phantom5702.com.conf
    server{
        listen      80;
        server_name k8syaml.phantom5702.com;

        location / {
            autoindex on;
            default_type text/plain;
            root /data/k8syaml;
        }
    }
    2.1 获取coredns的docker镜像
        以下操作可以在任意节点上完成,推荐在7.200上做,因为接下来制作coredns的k8s配置清单也是在运维主机7.200上创建后,再到node节点上应用  这里我选择在host2
        docker pull docker.io/coredns/coredns:1.6.1
        docker tag coredns:1.6.1 harbor.phantom5702.com/public/coredns:1.6.1
        docker push harbor.phantom5702.com/public/coredns:1.6.1

    2.2 创建coredns的资源配置清单
       以下资源配置清单,都是参考官网改出来的
       mkdir -p /data/k8syaml/coredns

        2.2.1 rbac集群权限清单

        cat >/data/k8syaml/coredns/rbac.yaml <<EOF
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: coredns
          namespace: kube-system
          labels:
              kubernetes.io/cluster-service: "true"
              addonmanager.kubernetes.io/mode: Reconcile
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          labels:
            kubernetes.io/bootstrapping: rbac-defaults
            addonmanager.kubernetes.io/mode: Reconcile
          name: system:coredns
        rules:
        - apiGroups:
          - ""
          resources:
          - endpoints
          - services
          - pods
          - namespaces
          verbs:
          - list
          - watch
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          annotations:
            rbac.authorization.kubernetes.io/autoupdate: "true"
          labels:
            kubernetes.io/bootstrapping: rbac-defaults
            addonmanager.kubernetes.io/mode: EnsureExists
          name: system:coredns
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: system:coredns
        subjects:
        - kind: ServiceAccount
          name: coredns
          namespace: kube-system
        EOF

        2.2.2 configmap配置清单
        cat >/data/k8syaml/coredns/cm.yaml <<EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: coredns
          namespace: kube-system
        data:
          Corefile: |
            .:53 {
                errors
                log
                health
                ready
                kubernetes cluster.local 192.168.0.0/16  #service资源cluster地址
                forward . 114.114.114.114   #上级DNS地址
                cache 30
                loop
                reload
                loadbalance
               }
        EOF

        2.2.3 depoly控制器清单

        cat >/data/k8syaml/coredns/dp.yaml <<EOF
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: coredns
          namespace: kube-system
          labels:
            k8s-app: coredns
            kubernetes.io/name: "CoreDNS"
        spec:
          replicas: 1
          selector:
            matchLabels:
              k8s-app: coredns
          template:
            metadata:
              labels:
                k8s-app: coredns
            spec:
              priorityClassName: system-cluster-critical
              serviceAccountName: coredns
              containers:
              - name: coredns
                image: harbor.phantom5702.com/public/coredns:1.6.1
                args:
                - -conf
                - /etc/coredns/Corefile
                volumeMounts:
                - name: config-volume
                  mountPath: /etc/coredns
                ports:
                - containerPort: 53
                  name: dns
                  protocol: UDP
                - containerPort: 53
                  name: dns-tcp
                  protocol: TCP
                - containerPort: 9153
                  name: metrics
                  protocol: TCP
                livenessProbe:
                  httpGet:
                    path: /health
                    port: 8080
                    scheme: HTTP
                  initialDelaySeconds: 60
                  timeoutSeconds: 5
                  successThreshold: 1
                  failureThreshold: 5
              dnsPolicy: Default
              volumes:
                - name: config-volume
                  configMap:
                    name: coredns
                    items:
                    - key: Corefile
                      path: Corefile
        EOF

        2.2.4 service资源清单

        cat >/data/k8syaml/coredns/svc.yaml <<EOF
        apiVersion: v1
        kind: Service
        metadata:
          name: coredns
          namespace: kube-system
          labels:
            k8s-app: coredns
            kubernetes.io/cluster-service: "true"
            kubernetes.io/name: "CoreDNS"
        spec:
          selector:
            k8s-app: coredns
          clusterIP: 192.168.0.2
          ports:
          - name: dns
            port: 53
            protocol: UDP
          - name: dns-tcp
            port: 53
          - name: metrics
            port: 9153
            protocol: TCP
        EOF

        资源配置清单根据官方 kubernetes 的 cluster addons  coredns 的yaml base


2.3.2 创建资源
    1.
        kubectl create -f http://k8syaml.phantom5702.com/coredns/rbac.yaml
        kubectl create -f http://k8syaml.phantom5702.com/coredns/cm.yaml
        kubectl create -f http://k8syaml.phantom5702.com/coredns/dp.yaml
        kubectl create -f http://k8syaml.phantom5702.com/coredns/svc.yaml
    2.
        ~]# kubectl get all -n kube-system
        NAME                           READY   STATUS    RESTARTS   AGE
        pod/coredns-7d57c9f676-fg2vj   1/1     Running   0          24s

        NAME              TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                  AGE
        service/coredns   ClusterIP   192.168.0.2   <none>        53/UDP,53/TCP,9153/TCP   19s    注意这里在kubelet.sh里配置了，不能改变

        NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
        deployment.apps/coredns   1/1     1            1           24s

        NAME                                 DESIRED   CURRENT   READY   AGE
        replicaset.apps/coredns-7d57c9f676   1         1         1       24s
    3.
        bin]# kubectl get pods  -o wide
        NAME             READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
        nginx-ds-b64sq   1/1     Running   0          12h   172.7.164.2   172.26.216.164   <none>           <none>
        nginx-ds-qqp94   1/1     Running   0          12h   172.7.163.2   172.26.216.163   <none>           <none>
    4. ~]# kubectl expose deployment nginx-ds --port=5002
      service/nginx-ds exposed

    5.bin]# dig -t A nginx-ds.default.svc.cluster.local @192.168.0.2 +short
      192.168.159.105


    6.在其中容器内部 能通过域名访问service
       /# curl nginx-ds.default
        <!doctype html>
        <html>
      :/# cat /etc/resolv.conf
        nameserver 192.168.0.2
        search default.svc.cluster.local svc.cluster.local cluster.local
        options ndots:5

    7. 文章中的操作
        2.3.5 创建一个service资源来验证
        先查看kube-public名称空间有没有pod
        ~]#  kubectl get pod  -n kube-public
        No resources found.
        # 之前我调试问题已经清理了所有的POD,所以没有
        如果没有则先创建pod
        kubectl create deployment nginx-dp --image=harbor.zq.com/public/nginx:v1.17.9 -n kube-public
        ~]# kubectl get deployments -n kube-public
        NAME       READY   UP-TO-DATE   AVAILABLE   AGE
        nginx-dp   1/1     1            1           35s
        ~]#  kubectl get pod  -n kube-public
        NAME                       READY   STATUS    RESTARTS   AGE
        nginx-dp-568f8dc55-rxvx2   1/1     Running   0          56s
        给pod创建一个service
        kubectl expose deployment nginx-dp --port=80 -n kube-public
        ~]# kubectl -n kube-public get service
        NAME       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
        nginx-dp   ClusterIP   192.168.63.255   <none>        80/TCP    11s
        验证是否可以解析
        ~]# dig -t A nginx-dp @192.168.0.2 +short
        # 发现无返回数据,难道解析不了
        # 其实是需要完整域名:服务名.名称空间.svc.cluster.local.
        ~]# dig -t A nginx-dp.kube-public.svc.cluster.local. @192.168.0.2 +short
        192.168.63.255
        可以看到我们没有手动添加任何解析记录，我们nginx-dp的service资源的IP，已经被解析了：
        进入到pod内部再次验证
        ~]# kubectl -n kube-public exec -it nginx-dp-568f8dc55-rxvx2 /bin/bash
        -qjwmz:/# apt update && apt install curl
        -qjwmz:/# ping nginx-dp
        PING nginx-dp.kube-public.svc.cluster.local (192.168.191.232): 56 data bytes
        64 bytes from 192.168.191.232: icmp_seq=0 ttl=64 time=0.184 ms
        64 bytes from 192.168.191.232: icmp_seq=1 ttl=64 time=0.225 ms
        为什么在容器中不用加全域名?
        -qjwmz:/# cat /etc/resolv.conf
        nameserver 192.168.0.2
        search kube-public.svc.cluster.local svc.cluster.local cluster.local host.com
        options ndots:5
        当我进入到pod内部以后，会发现我们的dns地址是我们的coredns地址，以及搜索域中已经添加了搜索域:kube-public.svc.cluster.local
        我们解决了在集群内部解析的问题，要想在集群外部访问我们的服务还需要igerss服务暴露功能
        现在，我们已经解决了在集群内部解析的问题，但是我们怎么做到在集群外部访问我们的服务呢？